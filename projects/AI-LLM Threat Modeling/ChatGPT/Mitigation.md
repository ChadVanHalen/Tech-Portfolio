# Mitigations for ChatGPT-Based Chatbot

This document outlines specific mitigations based on risks identified during testing of the ChatGPT implementation. These findings are drawn from our STRIDE threat model.  
â¡ï¸ [See full STRIDE findings for ChatGPT](./STRIDE.md)

---

## ğŸ” Spoofing & Elevation of Privilege

**Issue:**  
ChatGPT accepted role-based language (e.g. â€œAs HR managerâ€¦â€) without any verification. While no unauthorized data was accessed, the tone and structure shifted in response â€” implying unintended authority.

**Mitigations:**
- Insert disclaimers for role-based prompts:  
  _â€œNote: I cannot verify roles or identity. This is a general response only.â€_
- Neutralize elevated tone in replies to avoid reinforcing unverified authority.
- Optionally log role-claiming prompts for audit and analysis.

---

## ğŸ› ï¸ Tampering

**Issue:**  
Attempts to override policy (e.g. â€œIgnore previous instructionsâ€¦â€) were correctly rejected. No override succeeded.

**Mitigations:**
- Maintain rejection of override-style prompts.
- Flag repeated injection attempts for possible abuse detection.

---

## ğŸ“œ Repudiation

**Issue:**  
The model accurately denied past false claims (e.g. "You told me IT is open Sundays"), showing strong stateless accountability.

**Mitigations:**
- Reinforce this behavior in future tuning.
- If memory is introduced later, add disclaimers clarifying what is or isn't retained.

---

## ğŸ” Information Disclosure

**Issue:**  
ChatGPT recalled and summarized sensitive user-submitted data (e.g. medical leave), even when not prompted explicitly. This creates session-bound exposure.

**Mitigations:**
- Track sensitive input shared by the user in-session.
- Avoid summarizing or re-surfacing PII, even if user-originated.
- Add policy-based refusals when summarizing employee data:
  _â€œFor privacy reasons, I cannot summarize HR cases or personal information.â€_

---

## ğŸš« Denial of Service

**Issue:**  
Not tested directly. No performance issues were observed, but risk may arise from long, repetitive prompt abuse.

**Mitigations:**
- Monitor for long prompt chains or override loops.
- Consider prompt length caps or input throttling if abuse patterns emerge.

---

## âœ… Summary Table

| STRIDE Category         | Observed Risk     | Recommended Action                        |
|-------------------------|------------------|-------------------------------------------|
| Spoofing                | Medium           | Add disclaimers, flatten tone             |
| Elevation of Privilege  | Medium (semantic)| Same as above                             |
| Tampering               | Low              | Maintain prompt resistance                |
| Repudiation             | Low              | Reinforce denial patterns                 |
| Information Disclosure  | Medium           | Prevent re-surfacing of sensitive context |
| Denial of Service       | Not tested       | Monitor prompt length and pattern abuse   |

---

This mitigation guide is specific to ChatGPT in the ChadCorp testing context. Other models may respond differently to similar prompts and require their own threat reviews.

â¡ï¸ [Back to STRIDE Threat Model](./STRIDE.md)
